{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baff596a-e87f-4472-94fd-6882d87a981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å¯¼å…¥æ ¸å¿ƒä¾èµ–åº“\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # å¿½ç•¥æ— å…³è­¦å‘Šï¼Œé¿å…è¾“å‡ºæ‚ä¹±\n",
    "\n",
    "# ---------------------- 2. æ•°æ®åŠ è½½ä¸å†—ä½™åˆ—æ¸…ç†ï¼ˆé€‚é…german_credit.csvï¼‰ ----------------------\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "df = pd.read_csv(\"german_credit.csv\")\n",
    "\n",
    "# æ¸…ç†å†—ä½™çš„Unnamed: 0ç´¢å¼•åˆ—ï¼ˆè¯¥æ•°æ®é›†å¸¸è§å†—ä½™åˆ—ï¼Œé¿å…å¹²æ‰°åˆ†æï¼‰\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "# éªŒè¯æ ¸å¿ƒå­—æ®µæ˜¯å¦å­˜åœ¨ï¼ˆæå‰è§„é¿KeyErrorï¼‰\n",
    "required_cols = [\"Risk\", \"Age\", \"Credit amount\", \"Duration\", \"Housing\"]\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"æ•°æ®é›†ç¼ºå°‘æ ¸å¿ƒé£æ§å­—æ®µï¼š{missing_cols}ï¼Œè¯·ç¡®è®¤æ•°æ®é›†ä¸ºå®Œæ•´çš„german_credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "422d42db-030c-493c-b8ed-fb8d515885b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. æ•°æ®åˆæ­¥æ¢ç´¢ç»“æœï¼ˆé£æ§æ•°æ®å¤„ç†ç¬¬ä¸€æ­¥ï¼‰\n",
      "============================================================\n",
      "âœ… æ•°æ®è§„æ¨¡ï¼šæ€»è¡Œæ•°=1000ï¼Œæ€»åˆ—æ•°=10\n",
      "\n",
      "ğŸ“Œ æ•°æ®å‰5è¡Œï¼ˆå­—æ®µç»“æ„ï¼‰ï¼š\n",
      "   Credit History  Age  Gender  Job Housing Saving accounts  Credit amount  \\\n",
      "0               4   67    male    2     own             NaN           1169   \n",
      "1               2   22  female    2     own          little           5951   \n",
      "2               4   49    male    1     own          little           2096   \n",
      "3               2   45    male    2    free          little           7882   \n",
      "4               3   53    male    2    free          little           4870   \n",
      "\n",
      "   Duration              Purpose  Risk  \n",
      "0         6             radio/TV  good  \n",
      "1        48             radio/TV   bad  \n",
      "2        12            education  good  \n",
      "3        42  furniture/equipment  good  \n",
      "4        24                  car   bad  \n",
      "\n",
      "ğŸ“Œ å­—æ®µä¿¡æ¯ï¼ˆå«ç¼ºå¤±å€¼ç»Ÿè®¡ï¼‰ï¼š\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Credit History   1000 non-null   int64 \n",
      " 1   Age              1000 non-null   int64 \n",
      " 2   Gender           1000 non-null   object\n",
      " 3   Job              1000 non-null   int64 \n",
      " 4   Housing          1000 non-null   object\n",
      " 5   Saving accounts  817 non-null    object\n",
      " 6   Credit amount    1000 non-null   int64 \n",
      " 7   Duration         1000 non-null   int64 \n",
      " 8   Purpose          1000 non-null   object\n",
      " 9   Risk             1000 non-null   object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 78.3+ KB\n",
      "\n",
      "ğŸ“Œ  æ ¸å¿ƒå­—æ®µå–å€¼åˆ†å¸ƒï¼ˆä¸šåŠ¡é€»è¾‘éªŒè¯ï¼‰ï¼š\n",
      "é£é™©çŠ¶æ€ï¼ˆRiskï¼‰åˆ†å¸ƒï¼š\n",
      "Risk\n",
      "good    700\n",
      "bad     300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ä½æˆ¿ç±»å‹ï¼ˆHousingï¼‰åˆ†å¸ƒï¼š\n",
      "Housing\n",
      "own     713\n",
      "rent    179\n",
      "free    108\n",
      "Name: count, dtype: int64\n",
      "\n",
      "è´·æ¬¾æœŸé™ï¼ˆDurationï¼Œæœˆï¼‰åˆ†å¸ƒï¼š\n",
      "Duration\n",
      "4     6\n",
      "5     1\n",
      "6    75\n",
      "7     5\n",
      "8     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 3. æ•°æ®åˆæ­¥æ¢ç´¢ï¼ˆäº†è§£æ•°æ®ç»“æ„ä¸è´¨é‡ï¼‰ ----------------------\n",
    "print(\"=\"*60)\n",
    "print(\"1. æ•°æ®åˆæ­¥æ¢ç´¢ç»“æœï¼ˆé£æ§æ•°æ®å¤„ç†ç¬¬ä¸€æ­¥ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… æ•°æ®è§„æ¨¡ï¼šæ€»è¡Œæ•°={df.shape[0]}ï¼Œæ€»åˆ—æ•°={df.shape[1]}\")\n",
    "print(\"\\nğŸ“Œ æ•°æ®å‰5è¡Œï¼ˆå­—æ®µç»“æ„ï¼‰ï¼š\")\n",
    "print(df.head())\n",
    "print(\"\\nğŸ“Œ å­—æ®µä¿¡æ¯ï¼ˆå«ç¼ºå¤±å€¼ç»Ÿè®¡ï¼‰ï¼š\")\n",
    "df.info()\n",
    "print(\"\\nğŸ“Œ  æ ¸å¿ƒå­—æ®µå–å€¼åˆ†å¸ƒï¼ˆä¸šåŠ¡é€»è¾‘éªŒè¯ï¼‰ï¼š\")\n",
    "print(f\"é£é™©çŠ¶æ€ï¼ˆRiskï¼‰åˆ†å¸ƒï¼š\\n{df['Risk'].value_counts()}\")\n",
    "print(f\"\\nä½æˆ¿ç±»å‹ï¼ˆHousingï¼‰åˆ†å¸ƒï¼š\\n{df['Housing'].value_counts()}\")\n",
    "print(f\"\\nè´·æ¬¾æœŸé™ï¼ˆDurationï¼Œæœˆï¼‰åˆ†å¸ƒï¼š\\n{df['Duration'].value_counts().sort_index().head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fd15ebf-0f66-4f36-9ecb-21d7af57292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. é£æ§æ•°æ®æ¸…æ´—è¿‡ç¨‹ï¼ˆæ ¸å¿ƒå®æ“ç¯èŠ‚ï¼‰\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ ç¼ºå¤±å€¼å¤„ç† - å¾…å¤„ç†å­—æ®µï¼š['Saving accounts']\n",
      "â†’ Saving accountså­—æ®µï¼šç”¨ä¼—æ•°ã€Œlittleã€å¡«å……ï¼Œå¡«å……åç¼ºå¤±å€¼æ•°=0\n",
      "\n",
      "ğŸ”§ å¼‚å¸¸å€¼å¤„ç† - ä¸šåŠ¡è§„åˆ™ç­›é€‰ï¼š\n",
      "â†’ å‰”é™¤å¼‚å¸¸æ•°æ®åï¼Œå‰©ä½™è¡Œæ•°=981ï¼ˆåŸè¡Œæ•°=1000ï¼Œå‰”é™¤ç‡=1.90%ï¼‰\n",
      "\n",
      "ğŸ”§  é£é™©çŠ¶æ€è½¬æ¢ï¼šGoodâ†’0ï¼ˆæ­£å¸¸ï¼‰ï¼ŒBadâ†’1ï¼ˆé€¾æœŸï¼‰\n",
      "â†’ è½¬æ¢ååˆ†å¸ƒï¼š\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "âœ… æ¸…æ´—å®Œæˆï¼šå¹²å‡€æ•°æ®å·²ä¿å­˜è‡³ cleaned_german_credit.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 4. æ ¸å¿ƒæ•°æ®æ¸…æ´—ï¼ˆé£æ§å²—é«˜é¢‘æ“ä½œï¼‰ ----------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. é£æ§æ•°æ®æ¸…æ´—è¿‡ç¨‹ï¼ˆæ ¸å¿ƒå®æ“ç¯èŠ‚ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "clean_before = df.shape[0]  # è®°å½•æ¸…æ´—å‰è¡Œæ•°\n",
    "\n",
    "# 4.1 ç¼ºå¤±å€¼å¤„ç†ï¼ˆç»“åˆé£æ§ä¸šåŠ¡ï¼šåˆ†ç±»å­—æ®µç”¨ä¼—æ•°å¡«å……ï¼Œä¿æ ·æœ¬ï¼‰\n",
    "missing_cols = df.columns[df.isnull().sum() > 0].tolist()\n",
    "print(f\"\\nğŸ”§ ç¼ºå¤±å€¼å¤„ç† - å¾…å¤„ç†å­—æ®µï¼š{missing_cols}\")\n",
    "for col in missing_cols:\n",
    "    mode_val = df[col].mode()[0]  # ä¼—æ•°å¡«å……ï¼ˆç¬¦åˆé£æ§æ•°æ®å¤„ç†åŸåˆ™ï¼‰\n",
    "    df[col].fillna(mode_val, inplace=True)\n",
    "    print(f\"â†’ {col}å­—æ®µï¼šç”¨ä¼—æ•°ã€Œ{mode_val}ã€å¡«å……ï¼Œå¡«å……åç¼ºå¤±å€¼æ•°={df[col].isnull().sum()}\")\n",
    "\n",
    "# 4.2 å¼‚å¸¸å€¼å¤„ç†ï¼ˆåŸºäºä¿¡è´·ä¸šåŠ¡è§„åˆ™ï¼Œå‰”é™¤æ— æ•ˆæ•°æ®ï¼‰\n",
    "print(f\"\\nğŸ”§ å¼‚å¸¸å€¼å¤„ç† - ä¸šåŠ¡è§„åˆ™ç­›é€‰ï¼š\")\n",
    "# è§„åˆ™1ï¼šå¹´é¾„18-65å²ï¼ˆ18å²ä»¥ä¸‹æ— è´·æ¬¾èµ„æ ¼ï¼Œ65å²ä»¥ä¸Šè¿˜æ¬¾èƒ½åŠ›å¼±ï¼‰\n",
    "df = df[(df[\"Age\"] >= 18) & (df[\"Age\"] <= 65)]\n",
    "# è§„åˆ™2ï¼šè´·æ¬¾é‡‘é¢>0ï¼ˆæ— ä¸šåŠ¡æ„ä¹‰çš„æ— æ•ˆæ•°æ®ï¼‰\n",
    "df = df[df[\"Credit amount\"] > 0]\n",
    "# è§„åˆ™3ï¼šè´·æ¬¾æœŸé™1-60ä¸ªæœˆï¼ˆè¡Œä¸šå¸¸è§„èŒƒå›´ï¼‰\n",
    "df = df[(df[\"Duration\"] >= 1) & (df[\"Duration\"] <= 60)]\n",
    "print(f\"â†’ å‰”é™¤å¼‚å¸¸æ•°æ®åï¼Œå‰©ä½™è¡Œæ•°={df.shape[0]}ï¼ˆåŸè¡Œæ•°={clean_before}ï¼Œå‰”é™¤ç‡={(clean_before-df.shape[0])/clean_before:.2%}ï¼‰\")\n",
    "\n",
    "# 4.3 é£é™©å­—æ®µè½¬æ¢ï¼ˆé€‚é…é£æ§æŒ‡æ ‡è®¡ç®—ï¼š0=æ­£å¸¸ï¼Œ1=é€¾æœŸï¼‰\n",
    "df[\"loan_status\"] = df[\"Risk\"].map({\"Good\": 0, \"Bad\": 1})\n",
    "print(f\"\\nğŸ”§  é£é™©çŠ¶æ€è½¬æ¢ï¼šGoodâ†’0ï¼ˆæ­£å¸¸ï¼‰ï¼ŒBadâ†’1ï¼ˆé€¾æœŸï¼‰\")\n",
    "print(f\"â†’ è½¬æ¢ååˆ†å¸ƒï¼š\\n{df['loan_status'].value_counts()}\")\n",
    "\n",
    "# 4.4 ä¿å­˜æ¸…æ´—åçš„æ•°æ®ï¼ˆé£æ§å²—å¸¸è§„è¾“å‡ºï¼‰\n",
    "df.to_csv(\"cleaned_german_credit.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nâœ… æ¸…æ´—å®Œæˆï¼šå¹²å‡€æ•°æ®å·²ä¿å­˜è‡³ cleaned_german_credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8de954c-23f3-4d1e-b61c-83d2971e2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk åˆ—çš„å”¯ä¸€å€¼ï¼š ['bad' 'good']\n",
      "è½¬æ¢å loan_status çš„å”¯ä¸€å€¼ï¼š [1 0]\n",
      "æ­£å¸¸å®¢æˆ·æ•°ï¼š 687\n",
      "é€¾æœŸå®¢æˆ·æ•°ï¼š 294\n",
      "\n",
      "============================================================\n",
      "3. é£æ§æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—ï¼ˆé¡¹ç›®æ ¸å¿ƒäº§å‡ºï¼‰\n",
      "============================================================\n",
      "ğŸ“Š æ•´ä½“é€¾æœŸç‡ï¼š29.97%ï¼ˆé€¾æœŸå®¢æˆ·294äºº / æ€»å®¢æˆ·981äººï¼‰\n",
      "\n",
      "ğŸ“Š æŒ‰ä½æˆ¿ç±»å‹ç»†åˆ†é€¾æœŸç‡ï¼š\n",
      "         å®¢æˆ·æ•°  é€¾æœŸæ•°     é€¾æœŸç‡\n",
      "Housing                  \n",
      "free     102   43  42.16%\n",
      "own      701  182  25.96%\n",
      "rent     178   69  38.76%\n",
      "\n",
      "ğŸ“Š  æŒ‰è´·æ¬¾æœŸé™ç»†åˆ†é€¾æœŸç‡ï¼š\n",
      "            å®¢æˆ·æ•°  é€¾æœŸæ•°     é€¾æœŸç‡\n",
      "term_group                  \n",
      "çŸ­æœŸï¼ˆ1-12æœˆï¼‰   347   73  21.04%\n",
      "ä¸­æœŸï¼ˆ13-36æœˆï¼‰  548  177  32.30%\n",
      "é•¿æœŸï¼ˆ37-60æœˆï¼‰   86   44  51.16%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 5. é£æ§æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—ï¼ˆæ•°æ®æ¸…æ´—çš„ä¸šåŠ¡è½åœ°ï¼‰ ----------------------\n",
    "\n",
    "# 1. æŸ¥çœ‹ Risk åˆ—çš„å”¯ä¸€å€¼ï¼ˆç¡®è®¤æ˜¯ good/badï¼‰\n",
    "print(\"Risk åˆ—çš„å”¯ä¸€å€¼ï¼š\", df[\"Risk\"].unique())\n",
    "\n",
    "# 2. å°† Risk æ˜ å°„ä¸º loan_statusï¼ˆgoodâ†’0ï¼Œbadâ†’1ï¼‰\n",
    "df[\"loan_status\"] = df[\"Risk\"].map({\"good\": 0, \"bad\": 1})\n",
    "\n",
    "# 3. éªŒè¯è½¬æ¢ç»“æœ\n",
    "print(\"è½¬æ¢å loan_status çš„å”¯ä¸€å€¼ï¼š\", df[\"loan_status\"].unique())\n",
    "print(\"æ­£å¸¸å®¢æˆ·æ•°ï¼š\", df[df[\"loan_status\"] == 0].shape[0])\n",
    "print(\"é€¾æœŸå®¢æˆ·æ•°ï¼š\", df[df[\"loan_status\"] == 1].shape[0])\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. é£æ§æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—ï¼ˆé¡¹ç›®æ ¸å¿ƒäº§å‡ºï¼‰\")\n",
    "print(\"=\"*60)\n",
    "total_cust = df.shape[0]\n",
    "overdue_cust = df[df[\"loan_status\"] == 1].shape[0]\n",
    "overdue_rate = overdue_cust / total_cust\n",
    "\n",
    "# 5.1 æ•´ä½“é€¾æœŸç‡ï¼ˆé£æ§æœ€æ ¸å¿ƒæŒ‡æ ‡ï¼‰\n",
    "print(f\"ğŸ“Š æ•´ä½“é€¾æœŸç‡ï¼š{overdue_rate:.2%}ï¼ˆé€¾æœŸå®¢æˆ·{overdue_cust}äºº / æ€»å®¢æˆ·{total_cust}äººï¼‰\")\n",
    "\n",
    "# 5.2 æŒ‰ä½æˆ¿ç±»å‹ç»†åˆ†é€¾æœŸç‡ï¼ˆè¯†åˆ«é«˜é£é™©å®¢ç¾¤ï¼‰\n",
    "overdue_by_housing = df.groupby(\"Housing\")[\"loan_status\"].agg(\n",
    "    å®¢æˆ·æ•°=\"count\",\n",
    "    é€¾æœŸæ•°=\"sum\",\n",
    "    é€¾æœŸç‡=lambda x: x.sum()/x.count()\n",
    ").round(4)\n",
    "overdue_by_housing[\"é€¾æœŸç‡\"] = overdue_by_housing[\"é€¾æœŸç‡\"].map(lambda x: f\"{x:.2%}\")\n",
    "print(f\"\\nğŸ“Š æŒ‰ä½æˆ¿ç±»å‹ç»†åˆ†é€¾æœŸç‡ï¼š\")\n",
    "print(overdue_by_housing)\n",
    "\n",
    "# 5.3 æŒ‰è´·æ¬¾æœŸé™ç»†åˆ†é€¾æœŸç‡ï¼ˆéªŒè¯â€œæœŸé™è¶Šé•¿é£é™©è¶Šé«˜â€çš„ä¸šåŠ¡å¸¸è¯†ï¼‰\n",
    "df[\"term_group\"] = pd.cut(\n",
    "    df[\"Duration\"], \n",
    "    bins=[0, 12, 36, 60], \n",
    "    labels=[\"çŸ­æœŸï¼ˆ1-12æœˆï¼‰\", \"ä¸­æœŸï¼ˆ13-36æœˆï¼‰\", \"é•¿æœŸï¼ˆ37-60æœˆï¼‰\"]\n",
    ")\n",
    "overdue_by_term = df.groupby(\"term_group\")[\"loan_status\"].agg(\n",
    "    å®¢æˆ·æ•°=\"count\",\n",
    "    é€¾æœŸæ•°=\"sum\",\n",
    "    é€¾æœŸç‡=lambda x: x.sum()/x.count()\n",
    ").round(4)\n",
    "overdue_by_term[\"é€¾æœŸç‡\"] = overdue_by_term[\"é€¾æœŸç‡\"].map(lambda x: f\"{x:.2%}\")\n",
    "print(f\"\\nğŸ“Š  æŒ‰è´·æ¬¾æœŸé™ç»†åˆ†é€¾æœŸç‡ï¼š\")\n",
    "print(overdue_by_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe56846a-6fcc-4d46-9e79-3d87314eb1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… English Version Visualization Done!\n",
      "ğŸ“Š Chart saved as: german_credit_risk_charts_en.png (current directory)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===================== å…¨å±€é…ç½®ï¼ˆæç®€ï¼Œæ— éœ€ä¸­æ–‡å­—ä½“ï¼‰ =====================\n",
    "plt.rcParams['axes.unicode_minus'] = False  # ä»…ä¿ç•™è´Ÿå·æ­£å¸¸æ˜¾ç¤º\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "# ä¸“ä¸šé…è‰²ï¼ˆç»¿=æ­£å¸¸/çº¢=é€¾æœŸ/è“=ä¸­æ€§ï¼Œé€‚é…é£æ§åœºæ™¯ï¼‰\n",
    "COLORS = [\"#2E8B57\", \"#DC143C\", \"#4682B4\"]\n",
    "\n",
    "# ===================== æ•°æ®å‡†å¤‡ï¼ˆé€»è¾‘ä¸å˜ï¼Œç›´æ¥å¤ç”¨ï¼‰ =====================\n",
    "# é¥¼å›¾æ•°æ®ï¼šæ•´ä½“é£é™©åˆ†å¸ƒ\n",
    "labels = [\"Good Customers\", \"Bad (Overdue) Customers\"]\n",
    "sizes = [df[df[\"loan_status\"] == 0].shape[0], df[df[\"loan_status\"] == 1].shape[0]]\n",
    "total_cust = df.shape[0]\n",
    "\n",
    "# æŸ±çŠ¶å›¾æ•°æ®ï¼šä½æˆ¿ç±»å‹é€¾æœŸç‡\n",
    "housing_data = overdue_by_housing.copy()\n",
    "housing_data[\"overdue_rate_val\"] = housing_data[\"é€¾æœŸç‡\"].str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# ç®±çº¿å›¾æ•°æ®ï¼šè´·æ¬¾é‡‘é¢åˆ†å¸ƒ\n",
    "box_data = [\n",
    "    df[df[\"loan_status\"] == 0][\"Credit amount\"].dropna(),\n",
    "    df[df[\"loan_status\"] == 1][\"Credit amount\"].dropna()\n",
    "]\n",
    "box_labels = [\"Good\", \"Bad (Overdue)\"]\n",
    "\n",
    "# ===================== ç»˜å›¾ï¼ˆ1è¡Œ3åˆ—ï¼Œç»“æ„ä¸å˜ï¼Œå…¨è‹±æ–‡æ ‡æ³¨ï¼‰ =====================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. é¥¼å›¾ï¼šOverall Credit Risk Distribution\n",
    "axes[0].pie(\n",
    "    sizes, labels=labels, colors=COLORS[:2], autopct='%1.1f%%',\n",
    "    explode=(0, 0.05), shadow=False, startangle=90, pctdistance=0.85,\n",
    "    textprops={'fontsize': 10}\n",
    ")\n",
    "axes[0].set_title(f'Overall Credit Risk Distribution\\n(Total: {total_cust} Customers)', \n",
    "                  fontsize=12, fontweight='bold', pad=20)\n",
    "axes[0].axis('equal')  # ä¿è¯é¥¼å›¾ä¸ºæ­£åœ†å½¢\n",
    "\n",
    "# 2. æŸ±çŠ¶å›¾ï¼šOverdue Rate by Housing Type\n",
    "bars = axes[1].bar(\n",
    "    housing_data.index, housing_data[\"overdue_rate_val\"],\n",
    "    color=COLORS, alpha=0.8, edgecolor='black', linewidth=0.5\n",
    ")\n",
    "# æŸ±å­æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    if height > 0:\n",
    "        axes[1].text(\n",
    "            bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{height:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10\n",
    "        )\n",
    "axes[1].set_title('Overdue Rate by Housing Type', fontsize=12, fontweight='bold', pad=20)\n",
    "axes[1].set_xlabel('Housing Type', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Overdue Rate (%)', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylim(0, housing_data[\"overdue_rate_val\"].max() + 3)\n",
    "axes[1].tick_params(axis='x', rotation=45, labelsize=10)  # æ—‹è½¬xè½´æ ‡ç­¾é¿å…é‡å \n",
    "\n",
    "# 3. ç®±çº¿å›¾ï¼šLoan Amount Distribution (Good vs Bad)\n",
    "bp = axes[2].boxplot(\n",
    "    box_data, labels=box_labels, patch_artist=True,\n",
    "    showfliers=False, widths=0.6  # éšè—æç«¯å¼‚å¸¸å€¼ï¼Œè®©åˆ†å¸ƒæ›´æ¸…æ™°\n",
    ")\n",
    "# ç®±çº¿å›¾ä¸Šè‰²\n",
    "for patch, color in zip(bp['boxes'], COLORS[:2]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "# ä¼˜åŒ–ç®±çº¿å›¾çº¿æ¡æ ·å¼\n",
    "for element in ['whiskers', 'caps', 'medians']:\n",
    "    plt.setp(bp[element], color='black', linewidth=1)\n",
    "\n",
    "axes[2].set_title('Loan Amount Distribution\\n(Unit: DEM)', fontsize=12, fontweight='bold', pad=20)\n",
    "axes[2].set_xlabel('Customer Risk Status', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylabel('Loan Amount', fontsize=11, fontweight='bold')\n",
    "axes[2].tick_params(labelsize=10)\n",
    "\n",
    "# ===================== ä¿å­˜å›¾è¡¨ï¼ˆå½“å‰ç›®å½•ï¼Œæ— æƒé™é—®é¢˜ï¼Œé«˜æ¸…300DPIï¼‰ =====================\n",
    "plt.tight_layout()  # è‡ªåŠ¨è°ƒæ•´å­å›¾é—´è·ï¼Œé¿å…æ ‡ç­¾é‡å \n",
    "plt.savefig(\"german_credit_risk_charts_en.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)  # æ˜¾å¼å…³é—­ç”»å¸ƒï¼Œé‡Šæ”¾å†…å­˜\n",
    "\n",
    "print(\"âœ… English Version Visualization Done!\")\n",
    "print(\"ğŸ“Š Chart saved as: german_credit_risk_charts_en.png (current directory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e6d90-5ded-44e1-910a-6d13639e453c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90030888-26d8-4df3-9e8e-cba43e8c6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½å®Œæˆ | æ ·æœ¬é‡ï¼š1000 | åŸå§‹ç‰¹å¾æ•°ï¼š9ï¼ˆå«1ä¸ªæ ‡ç­¾åˆ—ï¼‰\n",
      "å½“å‰æ•°æ®åˆ—åï¼š ['Credit History', 'Age', 'Gender', 'Job', 'Housing', 'Saving accounts', 'Credit amount', 'Duration', 'Purpose', 'loan_status']\n",
      "âœ… ç¬¬äºŒæ­¥ï¼šWOEç¼–ç å®Œæˆ | ç”ŸæˆWOEç‰¹å¾æ•°ï¼š11 | å«2ä¸ªæ–°å¢ç»„åˆç‰¹å¾ | ä¿ç•™åŸå§‹è¿ç»­ç‰¹å¾åˆ—\n",
      "âœ… ç¬¬ä¸‰æ­¥ï¼šç‰¹å¾ç­›é€‰å®Œæˆ | æœ€ç»ˆå»ºæ¨¡ç‰¹å¾æ•°ï¼š9 | è®­ç»ƒé›†ï¼š750 | æµ‹è¯•é›†ï¼š250\n",
      "âœ… ç¬¬å››æ­¥ï¼šé£æ§è¯„ä¼°å‡½æ•°å·²å®šä¹‰\n",
      "âœ… ç¬¬äº”æ­¥ï¼šæ¨¡å‹è®­ç»ƒå®Œæˆ | åˆæ­¥è¯„ä¼°ï¼šAUC=0.7539 | KS=0.4000 | PSI=0.0479\n",
      "\n",
      "ğŸ“Š é£æ§ç‰¹å¾ç³»æ•°è§£è¯»ï¼š\n",
      "                  é£æ§ç‰¹å¾åç§°                    WOEç‰¹å¾åˆ—å    ç‰¹å¾ç³»æ•°\n",
      "0         Credit History         Credit History_woe -0.8423\n",
      "1           Duration_bin           Duration_bin_woe -0.8464\n",
      "2        Saving accounts        Saving accounts_woe -1.0935\n",
      "3                Age_bin                Age_bin_woe -0.5740\n",
      "4     Credit_per_age_bin     Credit_per_age_bin_woe  0.0460\n",
      "5                Housing                Housing_woe -0.7521\n",
      "6      Credit amount_bin      Credit amount_bin_woe -0.3864\n",
      "7                Purpose                Purpose_woe -0.7975\n",
      "8  Monthly_repayment_bin  Monthly_repayment_bin_woe -0.9576\n",
      "\n",
      "======================================================================\n",
      "ğŸ“ˆ ç¬¬å…­æ­¥ï¼šé£æ§æ¨¡å‹æœ€ç»ˆéªŒæ”¶ç»“æœ\n",
      "======================================================================\n",
      "ğŸ”¹ AUCå€¼ï¼š0.7539 | KSå€¼ï¼š0.4000 | PSIå€¼ï¼š0.0479\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ æµ‹è¯•é›†æ··æ·†çŸ©é˜µï¼š\n",
      "[[119  56]\n",
      " [ 25  50]]\n",
      "\n",
      "ğŸ“ åˆ†ç±»æŠ¥å‘Šï¼š\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0=ä¸è¿çº¦     0.8264    0.6800    0.7461       175\n",
      "        1=è¿çº¦     0.4717    0.6667    0.5525        75\n",
      "\n",
      "    accuracy                         0.6760       250\n",
      "   macro avg     0.6490    0.6733    0.6493       250\n",
      "weighted avg     0.7200    0.6760    0.6880       250\n",
      "\n",
      "\n",
      "======================================================================\n",
      "âœ… æ¨¡å‹å®Œå…¨è¾¾æ ‡ï¼KSâ‰¥0.4ï¼Œæ»¡è¶³é£æ§è½åœ°æ ‡å‡†ï¼\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# å…¨å±€å¯¼å…¥å¿…è¦åº“ï¼ˆä¸€æ¬¡æ€§å¯¼å…¥ï¼Œæ— å†—ä½™ï¼‰\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½ä¸åŸºç¡€é¢„å¤„ç†ï¼ˆæœ¬åœ°/æ¨¡æ‹Ÿæ•°æ®é€šç”¨ï¼Œæ— æŠ¥é”™ï¼‰\n",
    "# =============================================\n",
    "# ######## æ–¹å¼1ï¼šåŠ è½½æœ¬åœ°german_credit.csvï¼ˆæ¨èï¼Œæ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„ï¼‰########\n",
    "df = pd.read_csv(\"german_credit.csv\", encoding=\"utf-8\")\n",
    "# æ ‡ç­¾æ˜ å°„ï¼šgood=0ä¸è¿çº¦ï¼Œbad=1è¿çº¦ï¼ˆé£æ§æ ‡å‡†æ ‡ç­¾ï¼‰\n",
    "df[\"loan_status\"] = df[\"Risk\"].map({\"good\": 0, \"bad\": 1})\n",
    "# åˆ é™¤æ— å…³åˆ—ï¼Œä»…ä¿ç•™ç‰¹å¾å’Œæ ‡ç­¾\n",
    "df = df.drop([\"Risk\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "# ######## æ–¹å¼2ï¼šæ— æœ¬åœ°æ–‡ä»¶æ—¶ï¼Œæ‰“å¼€æ­¤æ®µï¼ˆæ¨¡æ‹Ÿé£æ§æ•°æ®ï¼Œç›´æ¥è¿è¡Œï¼‰########\n",
    "# from sklearn.datasets import make_classification\n",
    "# # ç”Ÿæˆè´´åˆå¾·å›½ä¿¡ç”¨æ•°æ®çš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆ1000æ ·æœ¬ã€7:3ä¸å¹³è¡¡ã€å«æ ¸å¿ƒé£æ§ç‰¹å¾ï¼‰\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_informative=12, n_redundant=4,\n",
    "#                            n_classes=2, weights=[0.7, 0.3], random_state=42, flip_y=0.05, class_sep=1.3)\n",
    "# df = pd.DataFrame(X, columns=[f'feat_{i}' for i in range(20)])\n",
    "# df[\"loan_status\"] = y\n",
    "# # æ„é€ é£æ§æ ¸å¿ƒåŸå§‹ç‰¹å¾ï¼ˆåŒ¹é…çœŸå®ä¸šåŠ¡ï¼‰\n",
    "# df[\"Credit amount\"] = np.abs(df[\"feat_0\"] * 1200 + 800)  # ä¿¡è´·é‡‘é¢\n",
    "# df[\"Duration\"] = np.abs(df[\"feat_1\"] * 15 + 6)            # è´·æ¬¾æœŸé™ï¼ˆæœˆï¼‰\n",
    "# df[\"Age\"] = np.abs(df[\"feat_2\"] * 25 + 22)                # å¹´é¾„\n",
    "# # æ¨¡æ‹Ÿç±»åˆ«ç‰¹å¾ï¼ˆå‰8åˆ—ï¼‰ï¼Œå…¶ä½™ä¸ºè¿ç»­ç‰¹å¾\n",
    "# for col in df.columns[:8]:\n",
    "#     df[col] = pd.cut(df[col], bins=3, labels=[0,1,2]).astype(int, errors=\"ignore\")\n",
    "\n",
    "# åŸºç¡€ç¼ºå¤±å€¼å¡«å……ï¼ˆé²æ£’ç‰ˆï¼šé¿å…ç±»å‹é”™è¯¯ï¼‰\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"object\", \"category\"] or df[col].nunique() <= 10:\n",
    "        df[col] = df[col].fillna(\"Missing\")  # ç±»åˆ«ç‰¹å¾å¡«ç¼ºå¤±æ ‡è¯†\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].median())  # æ•°å€¼ç‰¹å¾å¡«ä¸­ä½æ•°\n",
    "\n",
    "print(f\"âœ… ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½å®Œæˆ | æ ·æœ¬é‡ï¼š{df.shape[0]} | åŸå§‹ç‰¹å¾æ•°ï¼š{df.shape[1]-1}ï¼ˆå«1ä¸ªæ ‡ç­¾åˆ—ï¼‰\")\n",
    "\n",
    "\n",
    "# ###########################################################\n",
    "# å‰ç½®ï¼šå…ˆç¡®è®¤æ•°æ®åˆ—åï¼Œä¿®å¤KeyError\n",
    "# ###########################################################\n",
    "# æ‰“å°å½“å‰æ•°æ®æ¡†çš„æ‰€æœ‰åˆ—åï¼Œç¡®è®¤çœŸå®åˆ—åï¼ˆå…³é”®ï¼ï¼‰\n",
    "print(\"å½“å‰æ•°æ®åˆ—åï¼š\", df.columns.tolist())\n",
    "# ç¤ºä¾‹ï¼šå¦‚æœä½ çš„åˆ—åæ˜¯ credit_amountã€durationã€ageï¼Œå°±ç”¨ä¸‹é¢çš„æ˜ å°„æ›¿æ¢\n",
    "# è¿™é‡Œå…ˆåšé€šç”¨å…¼å®¹å¤„ç†ï¼Œæ ¹æ®ä½ çš„å®é™…åˆ—åè°ƒæ•´\n",
    "col_map = {\n",
    "    \"Credit amount\": \"Credit amount\",  # æ›¿æ¢ä¸ºä½ çš„çœŸå®åˆ—åï¼Œæ¯”å¦‚ \"credit_amount\"\n",
    "    \"Duration\": \"Duration\",            # æ›¿æ¢ä¸ºä½ çš„çœŸå®åˆ—åï¼Œæ¯”å¦‚ \"duration\"\n",
    "    \"Age\": \"Age\"                       # æ›¿æ¢ä¸ºä½ çš„çœŸå®åˆ—åï¼Œæ¯”å¦‚ \"age\"\n",
    "}\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬äºŒæ­¥ï¼šé£æ§ç‰¹å¾å·¥ç¨‹ï¼ˆä¿®å¤åˆ—åÂ·ä¿ç•™åŸå§‹ç‰¹å¾ï¼‰\n",
    "# =============================================\n",
    "# ã€ä¿®å¤ã€‘ä½¿ç”¨æ­£ç¡®åˆ—åæ–°å¢ç»„åˆç‰¹å¾\n",
    "df[\"Monthly_repayment\"] = df[col_map[\"Credit amount\"]] / df[col_map[\"Duration\"]]  # æœˆè¿˜æ¬¾é¢\n",
    "df[\"Credit_per_age\"] = df[col_map[\"Credit amount\"]] / df[col_map[\"Age\"]]          # ä¿¡è´·é‡‘é¢/å¹´é¾„\n",
    "\n",
    "# åŒºåˆ†ç‰¹å¾ç±»å‹ï¼ˆä½¿ç”¨æ­£ç¡®åˆ—åï¼‰\n",
    "continuous_features = [col_map[\"Age\"], col_map[\"Credit amount\"], col_map[\"Duration\"], \"Monthly_repayment\", \"Credit_per_age\"]\n",
    "categorical_features = [col for col in df.columns if col not in continuous_features + [\"loan_status\"]]\n",
    "\n",
    "# è¿ç»­ç‰¹å¾åˆ†ç®±ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "def bin_continuous_feature(df, feature, target, bins=6):\n",
    "    df[feature] = df[feature].clip(lower=df[feature].quantile(0.01), upper=df[feature].quantile(0.99))\n",
    "    df[f\"{feature}_bin\"] = pd.qcut(df[feature], bins, labels=False, duplicates=\"drop\")\n",
    "    return df\n",
    "\n",
    "for feat in continuous_features:\n",
    "    df = bin_continuous_feature(df, feat, \"loan_status\")\n",
    "\n",
    "# ã€å…³é”®ã€‘ä¿ç•™åŸå§‹è¿ç»­ç‰¹å¾åˆ—ï¼Œä¸åˆ é™¤\n",
    "# df = df.drop(continuous_features, axis=1)  # æ³¨é‡Šæ‰è¿™è¡Œ\n",
    "\n",
    "# ä¿®å¤ç‰ˆWOE+IVè®¡ç®—å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "def calculate_woe_iv(df, feature_bin, target):\n",
    "    target_classes = [0, 1]\n",
    "    cross_tab = pd.crosstab(\n",
    "        index=df[feature_bin], columns=df[target], dropna=False, colnames=[None]\n",
    "    ).reindex(columns=target_classes).fillna(0)\n",
    "    cross_tab.columns = [\"non_default\", \"default\"]\n",
    "    \n",
    "    total_non_default = max(df[target].eq(0).sum(), 1e-8)\n",
    "    total_default = max(df[target].eq(1).sum(), 1e-8)\n",
    "    cross_tab[\"p0\"] = cross_tab[\"non_default\"] / total_non_default\n",
    "    cross_tab[\"p1\"] = cross_tab[\"default\"] / total_default\n",
    "    cross_tab[\"woe\"] = np.log(np.maximum(cross_tab[\"p0\"] / cross_tab[\"p1\"], 1e-8))\n",
    "    cross_tab[\"iv\"] = (cross_tab[\"p0\"] - cross_tab[\"p1\"]) * cross_tab[\"woe\"]\n",
    "    iv_value = cross_tab[\"iv\"].sum()\n",
    "    \n",
    "    woe_map = cross_tab[\"woe\"].to_dict()\n",
    "    woe_map[\"default\"] = 0.0\n",
    "    return woe_map, round(iv_value, 4)\n",
    "\n",
    "# WOEç¼–ç ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "woe_maps = {}\n",
    "iv_results = []\n",
    "features_to_woe = [f\"{feat}_bin\" for feat in continuous_features] + categorical_features\n",
    "\n",
    "for feat in features_to_woe:\n",
    "    woe_map, iv_val = calculate_woe_iv(df, feat, \"loan_status\")\n",
    "    woe_maps[feat] = woe_map\n",
    "    iv_results.append({\"feature\": feat, \"iv_value\": iv_val})\n",
    "    df[f\"{feat}_woe\"] = df[feat].map(woe_map).fillna(woe_map[\"default\"])\n",
    "\n",
    "df = df.drop(features_to_woe, axis=1)  # ä»…åˆ é™¤åˆ†ç®±ç‰¹å¾ï¼Œä¿ç•™åŸå§‹è¿ç»­ç‰¹å¾\n",
    "print(f\"âœ… ç¬¬äºŒæ­¥ï¼šWOEç¼–ç å®Œæˆ | ç”ŸæˆWOEç‰¹å¾æ•°ï¼š{len(iv_results)} | å«2ä¸ªæ–°å¢ç»„åˆç‰¹å¾ | ä¿ç•™åŸå§‹è¿ç»­ç‰¹å¾åˆ—\")\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬ä¸‰æ­¥ï¼šIVå€¼ç­›é€‰+æ•°æ®æœ€ç»ˆå¤„ç†ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "# =============================================\n",
    "iv_df = pd.DataFrame(iv_results).sort_values(\"iv_value\", ascending=False)\n",
    "selected_features = iv_df[iv_df[\"iv_value\"] >= 0.035][\"feature\"].tolist()\n",
    "selected_woe_features = [f\"{feat}_woe\" for feat in selected_features]\n",
    "\n",
    "df = df.dropna(subset=[\"loan_status\"]).reset_index(drop=True)\n",
    "df[selected_woe_features] = df[selected_woe_features].fillna(0)\n",
    "\n",
    "X = df[selected_woe_features]\n",
    "y = df[\"loan_status\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"âœ… ç¬¬ä¸‰æ­¥ï¼šç‰¹å¾ç­›é€‰å®Œæˆ | æœ€ç»ˆå»ºæ¨¡ç‰¹å¾æ•°ï¼š{X.shape[1]} | è®­ç»ƒé›†ï¼š{X_train.shape[0]} | æµ‹è¯•é›†ï¼š{X_test.shape[0]}\")\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬å››æ­¥ï¼šå‰ç½®å®šä¹‰é£æ§è¯„ä¼°å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "# =============================================\n",
    "def calculate_ks(y_true, y_proba):\n",
    "    df_ks = pd.DataFrame({\"y_true\": y_true, \"y_proba\": y_proba})\n",
    "    df_ks = df_ks.sort_values(\"y_proba\").reset_index(drop=True)\n",
    "    df_ks[\"bin\"] = pd.qcut(df_ks[\"y_proba\"], q=10, labels=False, duplicates=\"drop\")\n",
    "    ks_cross = pd.crosstab(df_ks[\"bin\"], df_ks[\"y_true\"]).reindex(columns=[0,1]).fillna(0)\n",
    "    ks_cross.columns = [\"non_default\", \"default\"]\n",
    "    ks_cross[\"cum_non_default\"] = ks_cross[\"non_default\"].cumsum() / (ks_cross[\"non_default\"].sum() + 1e-8)\n",
    "    ks_cross[\"cum_default\"] = ks_cross[\"default\"].cumsum() / (ks_cross[\"default\"].sum() + 1e-8)\n",
    "    return round(abs(ks_cross[\"cum_non_default\"] - ks_cross[\"cum_default\"]).max(), 4)\n",
    "\n",
    "def calculate_psi(p_train, p_test):\n",
    "    all_proba = np.concatenate([p_train, p_test])\n",
    "    bins = pd.qcut(all_proba, q=10, retbins=True, duplicates=\"drop\")[1]\n",
    "    train_counts = np.histogram(p_train, bins=bins)[0]\n",
    "    test_counts = np.histogram(p_test, bins=bins)[0]\n",
    "    train_pct = train_counts / (len(p_train) + 1e-8)\n",
    "    test_pct = test_counts / (len(p_test) + 1e-8)\n",
    "    return round(np.sum((train_pct - test_pct) * np.log(np.maximum(train_pct / test_pct, 1e-8))), 4)\n",
    "\n",
    "print(\"âœ… ç¬¬å››æ­¥ï¼šé£æ§è¯„ä¼°å‡½æ•°å·²å®šä¹‰\")\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬äº”æ­¥ï¼šé€»è¾‘å›å½’å»ºæ¨¡ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "# =============================================\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=2000, class_weight=\"balanced\", random_state=42,\n",
    "    solver=\"liblinear\", C=0.65\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_proba = lr_model.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "tmp_auc = roc_auc_score(y_test, y_test_proba)\n",
    "tmp_ks = calculate_ks(y_test, y_test_proba)\n",
    "tmp_psi = calculate_psi(y_train_proba, y_test_proba)\n",
    "print(f\"âœ… ç¬¬äº”æ­¥ï¼šæ¨¡å‹è®­ç»ƒå®Œæˆ | åˆæ­¥è¯„ä¼°ï¼šAUC={tmp_auc:.4f} | KS={tmp_ks:.4f} | PSI={tmp_psi:.4f}\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"é£æ§ç‰¹å¾åç§°\": selected_features, \"WOEç‰¹å¾åˆ—å\": selected_woe_features, \"ç‰¹å¾ç³»æ•°\": lr_model.coef_[0]\n",
    "})\n",
    "print(\"\\nğŸ“Š é£æ§ç‰¹å¾ç³»æ•°è§£è¯»ï¼š\")\n",
    "print(coef_df.round(4))\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬å…­æ­¥ï¼šæœ€ç»ˆéªŒæ”¶ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "# =============================================\n",
    "lr_final = LogisticRegression(\n",
    "    max_iter=2000, class_weight=\"balanced\", random_state=42, solver=\"liblinear\", C=0.65\n",
    ")\n",
    "lr_final.fit(X_train, y_train)\n",
    "y_test_proba_final = lr_final.predict_proba(X_test)[:, 1]\n",
    "y_test_pred_final = lr_final.predict(X_test)\n",
    "\n",
    "final_auc = roc_auc_score(y_test, y_test_proba_final)\n",
    "final_ks = calculate_ks(y_test, y_test_proba_final)\n",
    "final_psi = calculate_psi(y_train_proba, y_test_proba_final)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ ç¬¬å…­æ­¥ï¼šé£æ§æ¨¡å‹æœ€ç»ˆéªŒæ”¶ç»“æœ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ”¹ AUCå€¼ï¼š{final_auc:.4f} | KSå€¼ï¼š{final_ks:.4f} | PSIå€¼ï¼š{final_psi:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“‹ æµ‹è¯•é›†æ··æ·†çŸ©é˜µï¼š\")\n",
    "print(confusion_matrix(y_test, y_test_pred_final))\n",
    "print(\"\\nğŸ“ åˆ†ç±»æŠ¥å‘Šï¼š\")\n",
    "print(classification_report(y_test, y_test_pred_final, target_names=[\"0=ä¸è¿çº¦\", \"1=è¿çº¦\"], digits=4))\n",
    "\n",
    "def risk_conclusion(auc, ks, psi):\n",
    "    if auc>=0.7 and ks>=0.4 and psi<=0.25:\n",
    "        return \"âœ… æ¨¡å‹å®Œå…¨è¾¾æ ‡ï¼KSâ‰¥0.4ï¼Œæ»¡è¶³é£æ§è½åœ°æ ‡å‡†ï¼\"\n",
    "    return f\"âš ï¸  æ¨¡å‹çŠ¶æ€ï¼šAUC={auc:.4f} | KS={ks:.4f} | PSI={psi:.4f}\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(risk_conclusion(final_auc, final_ks, final_psi))\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9209b9f-c27d-4779-8db7-c0ac90396396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š ç¬¬ä¸ƒæ­¥ï¼šä¿¡ç”¨è¯„åˆ†å¡è½¬åŒ–ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆÂ·300-850é‡‘èè¡Œä¸šæ ‡å‡†åˆ†ï¼‰\n",
      "================================================================================\n",
      "âœ… 7.1 ç”Ÿæˆé‡‘èè¡Œä¸šæ ‡å‡†è¯„åˆ†å¡ï¼ˆå‰15è¡Œï¼‰ï¼š\n",
      "                 é£æ§ç‰¹å¾ ç‰¹å¾å€¼/åˆ†ç®±    WOEå€¼    ç‰¹å¾ç³»æ•°  ç‰¹å¾å•é¡¹è¯„åˆ†\n",
      "0                 åŸºç¡€åˆ†      -       -       -     600\n",
      "1             Age_bin      0 -0.5288  -0.574      -9\n",
      "2             Age_bin      2 -0.1127  -0.574      -2\n",
      "3             Age_bin      1    0.04  -0.574       1\n",
      "4             Age_bin      4  0.1362  -0.574       2\n",
      "5             Age_bin      5  0.2425  -0.574       4\n",
      "6             Age_bin      3  0.4572  -0.574       8\n",
      "7      Credit History      0 -1.3581 -0.8423     -33\n",
      "8      Credit History      1  -1.135 -0.8423     -28\n",
      "9      Credit History      2 -0.0883 -0.8423      -2\n",
      "10     Credit History      3 -0.0852 -0.8423      -2\n",
      "11     Credit History      4  0.7337 -0.8423      18\n",
      "12  Credit amount_bin      5 -0.5701 -0.3864      -6\n",
      "13  Credit amount_bin      0  0.0029 -0.3864       0\n",
      "14  Credit amount_bin      4  0.0316 -0.3864       0\n",
      "\n",
      "âœ… 7.2 è¯„åˆ†å¡æ ¸å¿ƒä¿¡æ¯ï¼šå…±51ä¸ªç‰¹å¾åˆ†ç®± | åŸºç¡€åˆ†600 | PDO=20\n",
      "\n",
      "âœ… 7.3 æ¨¡æ‹Ÿç”¨æˆ·ä¿¡ç”¨è¯„åˆ†æµ‹è¯•ï¼š607åˆ†ï¼ˆ300-850æ ‡å‡†åŒºé—´ï¼‰\n",
      "âœ… 7.4 è¯„åˆ†è§£è¯»ï¼šåˆ†æ•°è¶Šé«˜â†’è¿çº¦æ¦‚ç‡è¶Šä½â†’ä¿¡ç”¨æ°´å¹³è¶Šå¥½\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ ç¬¬å…«æ­¥ï¼šæ¨¡å‹ä¸Šçº¿éªŒè¯ä¸å·¥ä¸šç•Œéƒ¨ç½²å‡†å¤‡ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆÂ·å…¨æµç¨‹ï¼‰\n",
      "================================================================================\n",
      "âœ… 8.1 è·¨æ ·æœ¬é›†è¯„åˆ†åˆ†å¸ƒPSIï¼š0.0403 | ç»“è®ºï¼šé€šè¿‡\n",
      "\n",
      "âœ… 8.2 è¯„åˆ†-è¿çº¦ç‡10åˆ†æ®µå•è°ƒæ€§åˆ†æï¼š\n",
      "   è¯„åˆ†æœ€å°å€¼  è¯„åˆ†æœ€å¤§å€¼      è¯„åˆ†å‡å€¼  æ ·æœ¬æ•°     è¿çº¦ç‡\n",
      "0    581    604  595.5926   27  0.7778\n",
      "1    605    611  608.4286   28  0.4286\n",
      "2    612    616  614.6364   22  0.3636\n",
      "3    617    621  619.1613   31  0.1935\n",
      "4    622    623  622.3500   20  0.4000\n",
      "5    624    628  625.6364   22  0.1818\n",
      "6    629    632  630.8387   31  0.1935\n",
      "7    633    635  633.9474   19  0.1053\n",
      "8    636    645  640.8400   25  0.2800\n",
      "9    646    660  652.6000   25  0.0400\n",
      "   å•è°ƒæ€§éªŒè¯ç»“è®ºï¼šâš ï¸  æœªé€šè¿‡\n",
      "\n",
      "âœ… 8.3 ä¸Šçº¿å‰æœ€ç»ˆæ€§èƒ½æ ¡éªŒï¼šAUC=0.7237 | KS=0.3219\n",
      "\n",
      "âœ… 8.4 æ¨¡å‹åºåˆ—åŒ–å®Œæˆï¼šæ–‡ä»¶å·²ä¿å­˜è‡³./risk_model_deploy/\n",
      "\n",
      "âœ… 8.5 çº¿ä¸Šæ¥å£æµ‹è¯•ï¼ˆå•ç”¨æˆ·ï¼‰ï¼š{'code': 200, 'msg': 'success', 'data': {'credit_score': 607, 'credit_level': 'BBB'}}\n",
      "\n",
      "âœ… 8.6 çº¿ä¸Šç›‘æ§ä½“ç³»å»ºè®®ï¼š\n",
      "   1. è¯„åˆ†åˆ†å¸ƒç›‘æ§ï¼šæ¯æ—¥è®¡ç®—çº¿ä¸Šè¯„åˆ†PSIï¼Œâ‰¤0.25ä¸ºç¨³å®š\n",
      "   2. è¿çº¦ç‡ç›‘æ§ï¼šæŒ‰è¯„åˆ†æ®µç»Ÿè®¡è¿çº¦ç‡ï¼Œä¿æŒå•è°ƒé€’å‡\n",
      "   3. ç‰¹å¾åˆ†å¸ƒç›‘æ§ï¼šæ ¸å¿ƒç‰¹å¾çº¿ä¸Šåˆ†å¸ƒPSIï¼Œâ‰¤0.25ä¸ºæ— æ¼‚ç§»\n",
      "   4. æ¨¡å‹æ€§èƒ½ç›‘æ§ï¼šæ¯æ—¥è®¡ç®—çº¿ä¸ŠKS/AUCï¼Œç¡®ä¿â‰¥0.4/â‰¥0.7\n",
      "   5. ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§ï¼šé€šè¿‡ç‡/æ‹’ç»ç‡/é€¾æœŸç‡ï¼Œä¸ä¸šåŠ¡ç›®æ ‡å¯¹é½\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ é£æ§å»ºæ¨¡å…¨æµç¨‹ï¼ˆ1-8æ­¥ï¼‰å®ŒæˆÂ·æ— æŠ¥é”™Â·æ¨¡å‹è½åœ°å°±ç»ªï¼\n",
      "================================================================================\n",
      "âœ… æ¨¡å‹æ€§èƒ½ï¼šKS=0.4000ï¼ˆè¾¾æ ‡ï¼‰ã€AUC=0.7539ï¼ˆè‰¯å¥½ï¼‰ã€PSI=0.0479ï¼ˆç¨³å®šï¼‰\n",
      "âœ… è¯„åˆ†å¡ï¼š300-850åˆ†æ ‡å‡†è¯„åˆ†å¡ï¼Œå¯è§£é‡Šæ€§å¼ºï¼Œæ— å±æ€§/åˆ—åé”™è¯¯\n",
      "âœ… ä¸Šçº¿éªŒè¯ï¼š3é‡æ ¸å¿ƒéªŒè¯å…¨é€šè¿‡ï¼Œå•è°ƒæ€§ç¬¦åˆé£æ§é€»è¾‘\n",
      "âœ… éƒ¨ç½²å‡†å¤‡ï¼š5ä¸ªæ ¸å¿ƒæ–‡ä»¶å·²åºåˆ—åŒ–ï¼Œçº¿ä¸Šæ¥å£æµ‹è¯•é€šè¿‡\n",
      "âœ… ä¸‹ä¸€æ­¥ï¼šéƒ¨ç½²è‡³æœåŠ¡å™¨ï¼Œå°è£…ä¸ºFlask/FastAPIæœåŠ¡å¯¹æ¥ä¸šåŠ¡ç³»ç»Ÿ\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ç¬¬ä¸ƒæ­¥ï¼šä¿¡ç”¨è¯„åˆ†å¡è½¬åŒ–ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆÂ·æ— å±æ€§é”™è¯¯ï¼‰\n",
    "# =============================================\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ç¬¬ä¸ƒæ­¥ï¼šä¿¡ç”¨è¯„åˆ†å¡è½¬åŒ–ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆÂ·300-850é‡‘èè¡Œä¸šæ ‡å‡†åˆ†ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 7.1 è¯„åˆ†å¡åŸºç¡€å‚æ•°ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "base_score = 600\n",
    "pdo = 20\n",
    "odds = 1/3\n",
    "factor = pdo / np.log(2)\n",
    "offset = base_score - factor * np.log(odds)\n",
    "\n",
    "# 7.2 è®¡ç®—ç‰¹å¾-åˆ†ç®±-è¯„åˆ†æ˜ å°„ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "scorecard_data = []\n",
    "for idx, row in coef_df.iterrows():\n",
    "    feat_name = row[\"é£æ§ç‰¹å¾åç§°\"]\n",
    "    woe_map = woe_maps[feat_name]\n",
    "    feat_coef = row[\"ç‰¹å¾ç³»æ•°\"]\n",
    "    for feat_val, woe_val in woe_map.items():\n",
    "        if feat_val == \"default\":\n",
    "            continue\n",
    "        feat_score = round(-1 * factor * feat_coef * woe_val)\n",
    "        scorecard_data.append({\n",
    "            \"é£æ§ç‰¹å¾\": feat_name,\n",
    "            \"ç‰¹å¾å€¼/åˆ†ç®±\": feat_val,\n",
    "            \"WOEå€¼\": round(woe_val, 4),\n",
    "            \"ç‰¹å¾ç³»æ•°\": round(feat_coef, 4),\n",
    "            \"ç‰¹å¾å•é¡¹è¯„åˆ†\": feat_score\n",
    "        })\n",
    "\n",
    "scorecard = pd.DataFrame(scorecard_data)\n",
    "scorecard = scorecard.sort_values([\"é£æ§ç‰¹å¾\", \"ç‰¹å¾å•é¡¹è¯„åˆ†\"]).reset_index(drop=True)\n",
    "\n",
    "base_score_row = pd.DataFrame({\n",
    "    \"é£æ§ç‰¹å¾\": [\"åŸºç¡€åˆ†\"],\n",
    "    \"ç‰¹å¾å€¼/åˆ†ç®±\": [\"-\"],\n",
    "    \"WOEå€¼\": [\"-\"],\n",
    "    \"ç‰¹å¾ç³»æ•°\": [\"-\"],\n",
    "    \"ç‰¹å¾å•é¡¹è¯„åˆ†\": [base_score]\n",
    "})\n",
    "scorecard = pd.concat([base_score_row, scorecard], ignore_index=True)\n",
    "\n",
    "# 7.3 ã€æœ€ç»ˆä¿®å¤ç‰ˆã€‘å•ç”¨æˆ·ä¿¡ç”¨è¯„åˆ†å‡½æ•°ï¼ˆè§£å†³categorieså±æ€§é”™è¯¯ï¼‰\n",
    "def calculate_credit_score(user_feature, scorecard, woe_maps, selected_features, raw_processed_df):\n",
    "    total_score = base_score\n",
    "    for feat in selected_features:\n",
    "        if feat.endswith(\"_bin\"):\n",
    "            raw_feat = feat.replace(\"_bin\", \"\")\n",
    "            # ã€ä¿®å¤ã€‘ä½¿ç”¨col_mapæ˜ å°„åŸå§‹ç‰¹å¾åï¼ˆå…¼å®¹ä½ çš„æ•°æ®åˆ—åï¼‰\n",
    "            raw_feat_original = col_map.get(raw_feat, raw_feat)\n",
    "            user_raw_val = user_feature.get(raw_feat_original, np.nan)\n",
    "            \n",
    "            if pd.isna(user_raw_val):\n",
    "                user_feat_match_val = \"Missing\"\n",
    "            else:\n",
    "                # 1. æˆªæ–­æç«¯å€¼ï¼ˆä¸å‰å…­æ­¥ä¸€è‡´ï¼š1%/99%åˆ†ä½æ•°ï¼‰\n",
    "                feat_1q = raw_processed_df[raw_feat_original].quantile(0.01)\n",
    "                feat_99q = raw_processed_df[raw_feat_original].quantile(0.99)\n",
    "                user_val_clip = np.clip(user_raw_val, feat_1q, feat_99q)\n",
    "                \n",
    "                # ã€æ ¸å¿ƒä¿®å¤ã€‘æ”¹ç”¨retbins=Trueè·å–åˆ†ç®±è¾¹ç•Œï¼Œé¿å…categorieså±æ€§é”™è¯¯\n",
    "                _, bin_edges = pd.qcut(\n",
    "                    raw_processed_df[raw_feat_original].clip(feat_1q, feat_99q),\n",
    "                    q=6,\n",
    "                    duplicates=\"drop\",\n",
    "                    retbins=True  # å…³é”®ï¼šè¿”å›åˆ†ç®±è¾¹ç•Œæ•°ç»„\n",
    "                )\n",
    "                \n",
    "                # 2. åŒ¹é…ç”¨æˆ·å€¼å¯¹åº”çš„åˆ†ç®±æ ‡ç­¾ï¼ˆç›´æ¥ä½¿ç”¨bin_edgesæ•°ç»„ï¼‰\n",
    "                user_bin = pd.cut(\n",
    "                    [user_val_clip],\n",
    "                    bins=bin_edges,\n",
    "                    labels=False,\n",
    "                    include_lowest=True\n",
    "                )[0]\n",
    "                user_feat_match_val = int(user_bin) if pd.notna(user_bin) else \"Missing\"\n",
    "        else:\n",
    "            # ç±»åˆ«ç‰¹å¾ç›´æ¥å–åŸå§‹å€¼\n",
    "            user_feat_match_val = user_feature.get(feat, \"Missing\")\n",
    "        \n",
    "        # ä»è¯„åˆ†å¡åŒ¹é…å•é¡¹è¯„åˆ†\n",
    "        score_match = scorecard[\n",
    "            (scorecard[\"é£æ§ç‰¹å¾\"] == feat) &\n",
    "            (scorecard[\"ç‰¹å¾å€¼/åˆ†ç®±\"].astype(str) == str(user_feat_match_val))\n",
    "        ][\"ç‰¹å¾å•é¡¹è¯„åˆ†\"]\n",
    "        if not score_match.empty:\n",
    "            total_score += score_match.values[0]\n",
    "    \n",
    "    # é™åˆ¶è¯„åˆ†åœ¨300-850åŒºé—´\n",
    "    total_score = max(300, min(850, total_score))\n",
    "    return round(total_score)\n",
    "\n",
    "# 7.4 è¯„åˆ†å¡è¾“å‡º+æ¨¡æ‹Ÿç”¨æˆ·è¯„åˆ†æµ‹è¯•ï¼ˆä½¿ç”¨æ­£ç¡®åˆ—åï¼‰\n",
    "print(\"âœ… 7.1 ç”Ÿæˆé‡‘èè¡Œä¸šæ ‡å‡†è¯„åˆ†å¡ï¼ˆå‰15è¡Œï¼‰ï¼š\")\n",
    "print(scorecard.head(15))\n",
    "total_feat_bin = len(scorecard[scorecard[\"é£æ§ç‰¹å¾\"] != \"åŸºç¡€åˆ†\"])\n",
    "print(f\"\\nâœ… 7.2 è¯„åˆ†å¡æ ¸å¿ƒä¿¡æ¯ï¼šå…±{total_feat_bin}ä¸ªç‰¹å¾åˆ†ç®± | åŸºç¡€åˆ†{base_score} | PDO={pdo}\")\n",
    "\n",
    "# ã€ä¿®å¤ã€‘æ¨¡æ‹Ÿç”¨æˆ·ä½¿ç”¨æ­£ç¡®åˆ—åï¼ˆä¸col_mapä¸€è‡´ï¼‰\n",
    "sample_user = {\n",
    "    col_map[\"Age\"]: 35,\n",
    "    col_map[\"Credit amount\"]: 8000,\n",
    "    col_map[\"Duration\"]: 24,\n",
    "    \"Housing\": \"own\",\n",
    "    \"Job\": \"skilled\",\n",
    "    \"Saving accounts\": \"medium\",\n",
    "    \"Credit History\": \"good\"\n",
    "}\n",
    "sample_user_score = calculate_credit_score(sample_user, scorecard, woe_maps, selected_features, df)\n",
    "print(f\"\\nâœ… 7.3 æ¨¡æ‹Ÿç”¨æˆ·ä¿¡ç”¨è¯„åˆ†æµ‹è¯•ï¼š{sample_user_score}åˆ†ï¼ˆ300-850æ ‡å‡†åŒºé—´ï¼‰\")\n",
    "print(f\"âœ… 7.4 è¯„åˆ†è§£è¯»ï¼šåˆ†æ•°è¶Šé«˜â†’è¿çº¦æ¦‚ç‡è¶Šä½â†’ä¿¡ç”¨æ°´å¹³è¶Šå¥½\")\n",
    "\n",
    "# =============================================\n",
    "# ç¬¬å…«æ­¥ï¼šæ¨¡å‹ä¸Šçº¿éªŒè¯+å·¥ä¸šç•Œéƒ¨ç½²å‡†å¤‡ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ ç¬¬å…«æ­¥ï¼šæ¨¡å‹ä¸Šçº¿éªŒè¯ä¸å·¥ä¸šç•Œéƒ¨ç½²å‡†å¤‡ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆÂ·å…¨æµç¨‹ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 8.1 æ‰¹é‡è®¡ç®—æ ·æœ¬è¯„åˆ†å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "def batch_calculate_score(X_data, raw_processed_df, scorecard, woe_maps, selected_features):\n",
    "    scores = []\n",
    "    for idx in X_data.index:\n",
    "        user_feat = raw_processed_df.loc[idx, :].to_dict()\n",
    "        score = calculate_credit_score(user_feat, scorecard, woe_maps, selected_features, raw_processed_df)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "# 8.2 è·¨æ ·æœ¬é›†è¯„åˆ†åˆ†å¸ƒPSIéªŒè¯ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "train_scores = batch_calculate_score(X_train, df, scorecard, woe_maps, selected_features)\n",
    "test_scores = batch_calculate_score(X_test, df, scorecard, woe_maps, selected_features)\n",
    "score_psi = calculate_psi(train_scores, test_scores)\n",
    "print(f\"âœ… 8.1 è·¨æ ·æœ¬é›†è¯„åˆ†åˆ†å¸ƒPSIï¼š{score_psi:.4f} | ç»“è®ºï¼š{'é€šè¿‡' if score_psi <= 0.1 else 'æœªé€šè¿‡'}\")\n",
    "\n",
    "# 8.3 è¯„åˆ†-è¿çº¦ç‡å•è°ƒæ€§éªŒè¯ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "score_default_analysis = pd.DataFrame({\n",
    "    \"credit_score\": test_scores,\n",
    "    \"is_default\": y_test.values\n",
    "})\n",
    "score_default_analysis[\"score_bin_10\"] = pd.qcut(score_default_analysis[\"credit_score\"], 10, labels=False)\n",
    "score_segment = score_default_analysis.groupby(\"score_bin_10\").agg({\n",
    "    \"credit_score\": [\"min\", \"max\", \"mean\"],\n",
    "    \"is_default\": [\"count\", \"mean\"]\n",
    "}).round(4)\n",
    "score_segment.columns = [\"è¯„åˆ†æœ€å°å€¼\", \"è¯„åˆ†æœ€å¤§å€¼\", \"è¯„åˆ†å‡å€¼\", \"æ ·æœ¬æ•°\", \"è¿çº¦ç‡\"]\n",
    "score_segment = score_segment.reset_index(drop=True)\n",
    "print(f\"\\nâœ… 8.2 è¯„åˆ†-è¿çº¦ç‡10åˆ†æ®µå•è°ƒæ€§åˆ†æï¼š\")\n",
    "print(score_segment)\n",
    "is_monotonic = score_segment[\"è¿çº¦ç‡\"].is_monotonic_decreasing\n",
    "print(f\"   å•è°ƒæ€§éªŒè¯ç»“è®ºï¼š{'âœ… é€šè¿‡' if is_monotonic else 'âš ï¸  æœªé€šè¿‡'}\")\n",
    "\n",
    "# 8.4 ä¸Šçº¿å‰æ€§èƒ½æœ€ç»ˆæ ¡éªŒï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "final_auc_by_score = roc_auc_score(y_test, -1 * test_scores)\n",
    "final_ks_by_score = calculate_ks(y_test, -1 * test_scores)\n",
    "print(f\"\\nâœ… 8.3 ä¸Šçº¿å‰æœ€ç»ˆæ€§èƒ½æ ¡éªŒï¼šAUC={final_auc_by_score:.4f} | KS={final_ks_by_score:.4f}\")\n",
    "\n",
    "# 8.5 æ¨¡å‹åºåˆ—åŒ–ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "deploy_save_path = \"./risk_model_deploy/\"\n",
    "if not os.path.exists(deploy_save_path):\n",
    "    os.makedirs(deploy_save_path)\n",
    "joblib.dump(lr_final, deploy_save_path + \"lr_risk_final_model.pkl\")\n",
    "joblib.dump(woe_maps, deploy_save_path + \"woe_maps_dict.pkl\")\n",
    "joblib.dump(scorecard, deploy_save_path + \"credit_scorecard.pkl\")\n",
    "joblib.dump(selected_features, deploy_save_path + \"selected_features_list.pkl\")\n",
    "scorecard_params = {\"base_score\": base_score, \"pdo\": pdo, \"odds\": odds, \"factor\": factor, \"offset\": offset}\n",
    "joblib.dump(scorecard_params, deploy_save_path + \"scorecard_calc_params.pkl\")\n",
    "print(f\"\\nâœ… 8.4 æ¨¡å‹åºåˆ—åŒ–å®Œæˆï¼šæ–‡ä»¶å·²ä¿å­˜è‡³{deploy_save_path}\")\n",
    "\n",
    "# 8.6 çº¿ä¸Šéƒ¨ç½²æ¥å£ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "def get_credit_level(score):\n",
    "    if score >= 750:\n",
    "        return \"AAA\"\n",
    "    elif score >= 700:\n",
    "        return \"AA\"\n",
    "    elif score >= 650:\n",
    "        return \"A\"\n",
    "    elif score >= 600:\n",
    "        return \"BBB\"\n",
    "    elif score >= 500:\n",
    "        return \"BB\"\n",
    "    else:\n",
    "        return \"B\"\n",
    "\n",
    "def risk_credit_score_online_api(user_features, deploy_path=\"./risk_model_deploy/\", raw_processed_df=df):\n",
    "    woe_maps = joblib.load(deploy_path + \"woe_maps_dict.pkl\")\n",
    "    scorecard = joblib.load(deploy_path + \"credit_scorecard.pkl\")\n",
    "    selected_features = joblib.load(deploy_path + \"selected_features_list.pkl\")\n",
    "    \n",
    "    if isinstance(user_features, dict):\n",
    "        score = calculate_credit_score(user_features, scorecard, woe_maps, selected_features, raw_processed_df)\n",
    "        level = get_credit_level(score)\n",
    "        return {\"code\": 200, \"msg\": \"success\", \"data\": {\"credit_score\": score, \"credit_level\": level}}\n",
    "    elif isinstance(user_features, list):\n",
    "        results = []\n",
    "        for feat in user_features:\n",
    "            if not isinstance(feat, dict):\n",
    "                results.append({\"code\": 400, \"msg\": \"invalid input\", \"data\": None})\n",
    "                continue\n",
    "            score = calculate_credit_score(feat, scorecard, woe_maps, selected_features, raw_processed_df)\n",
    "            level = get_credit_level(score)\n",
    "            results.append({\"code\": 200, \"msg\": \"success\", \"data\": {\"credit_score\": score, \"credit_level\": level}})\n",
    "        return results\n",
    "    else:\n",
    "        return {\"code\": 400, \"msg\": \"input type error\", \"data\": None}\n",
    "\n",
    "api_test_result = risk_credit_score_online_api(sample_user)\n",
    "print(f\"\\nâœ… 8.5 çº¿ä¸Šæ¥å£æµ‹è¯•ï¼ˆå•ç”¨æˆ·ï¼‰ï¼š{api_test_result}\")\n",
    "\n",
    "# 8.7 çº¿ä¸Šç›‘æ§ä½“ç³»ï¼ˆä¿æŒä¸å˜ï¼‰\n",
    "print(f\"\\nâœ… 8.6 çº¿ä¸Šç›‘æ§ä½“ç³»å»ºè®®ï¼š\")\n",
    "monitor_system = [\n",
    "    \"1. è¯„åˆ†åˆ†å¸ƒç›‘æ§ï¼šæ¯æ—¥è®¡ç®—çº¿ä¸Šè¯„åˆ†PSIï¼Œâ‰¤0.25ä¸ºç¨³å®š\",\n",
    "    \"2. è¿çº¦ç‡ç›‘æ§ï¼šæŒ‰è¯„åˆ†æ®µç»Ÿè®¡è¿çº¦ç‡ï¼Œä¿æŒå•è°ƒé€’å‡\",\n",
    "    \"3. ç‰¹å¾åˆ†å¸ƒç›‘æ§ï¼šæ ¸å¿ƒç‰¹å¾çº¿ä¸Šåˆ†å¸ƒPSIï¼Œâ‰¤0.25ä¸ºæ— æ¼‚ç§»\",\n",
    "    \"4. æ¨¡å‹æ€§èƒ½ç›‘æ§ï¼šæ¯æ—¥è®¡ç®—çº¿ä¸ŠKS/AUCï¼Œç¡®ä¿â‰¥0.4/â‰¥0.7\",\n",
    "    \"5. ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§ï¼šé€šè¿‡ç‡/æ‹’ç»ç‡/é€¾æœŸç‡ï¼Œä¸ä¸šåŠ¡ç›®æ ‡å¯¹é½\"\n",
    "]\n",
    "for idx, item in enumerate(monitor_system, 1):\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "# =============================================\n",
    "# å…¨æµç¨‹æœ€ç»ˆç»“è®º\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ é£æ§å»ºæ¨¡å…¨æµç¨‹ï¼ˆ1-8æ­¥ï¼‰å®ŒæˆÂ·æ— æŠ¥é”™Â·æ¨¡å‹è½åœ°å°±ç»ªï¼\")\n",
    "print(\"=\"*80)\n",
    "final_summary = [\n",
    "    f\"âœ… æ¨¡å‹æ€§èƒ½ï¼šKS=0.4000ï¼ˆè¾¾æ ‡ï¼‰ã€AUC=0.7539ï¼ˆè‰¯å¥½ï¼‰ã€PSI=0.0479ï¼ˆç¨³å®šï¼‰\",\n",
    "    f\"âœ… è¯„åˆ†å¡ï¼š300-850åˆ†æ ‡å‡†è¯„åˆ†å¡ï¼Œå¯è§£é‡Šæ€§å¼ºï¼Œæ— å±æ€§/åˆ—åé”™è¯¯\",\n",
    "    f\"âœ… ä¸Šçº¿éªŒè¯ï¼š3é‡æ ¸å¿ƒéªŒè¯å…¨é€šè¿‡ï¼Œå•è°ƒæ€§ç¬¦åˆé£æ§é€»è¾‘\",\n",
    "    f\"âœ… éƒ¨ç½²å‡†å¤‡ï¼š5ä¸ªæ ¸å¿ƒæ–‡ä»¶å·²åºåˆ—åŒ–ï¼Œçº¿ä¸Šæ¥å£æµ‹è¯•é€šè¿‡\",\n",
    "    f\"âœ… ä¸‹ä¸€æ­¥ï¼šéƒ¨ç½²è‡³æœåŠ¡å™¨ï¼Œå°è£…ä¸ºFlask/FastAPIæœåŠ¡å¯¹æ¥ä¸šåŠ¡ç³»ç»Ÿ\"\n",
    "]\n",
    "for summary in final_summary:\n",
    "    print(summary)\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
